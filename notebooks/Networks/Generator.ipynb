{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82aa3b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from helper import supress_tracer_warnings, assert_shape, is_list_of_str, normalise_2nd_moment\n",
    "\n",
    "from typing import Optional, Any, List\n",
    "import numpy as np\n",
    "\n",
    "from shared import FullyConnectedLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c115635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "cur_path = ''.join(os.getcwd().split('/')[:-1])\n",
    "sys.path.insert(0, f'{cur_path}/torch_utils/ops')\n",
    "sys.path.insert(0, f'{cur_path}/torch_utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daec8e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import conv2d_resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca63337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modulated_conv2d(x: torch.Tensor, weight: torch.Tensor, styles: torch.Tensor, noise: Optional[torch.Tensor] = None,\n",
    "                     up: int = 1, down: int = 1, padding: int = 0, resample_filter: Optional[List[int]] = None, \n",
    "                     demodulate: bool = True, flip_weight: bool = True, fused_mod_cov: bool = True) -> torch.Tensor:\n",
    "    \n",
    "    # x:      [B, inC, H, W]\n",
    "    # weight: [outC, inC, kh, kw]\n",
    "    # styles: [B, inC]\n",
    "\n",
    "    batch_size = x.shape[0]\n",
    "    out_channels, in_channels, kw, kh = weight.shape\n",
    "    assert_shape(weight, [out_channels, in_channels, kw, kh])\n",
    "    assert_shape(x, [batch_size, in_channels, None, None])    # x's & weight's batch_size and In channels must remain same\n",
    "    assert_shape(styles, [batch_size, in_channels])\n",
    "\n",
    "    if x.dtype == torch.float16 and demodulate:\n",
    "        a = 1 / np.sqrt(in_channels * kh * kw)\n",
    "        b = weight.norm(p = float(\"inf\"), dim = [1,2,3], keepdim=True)          # max of inC, kh, kw\n",
    "        weight = weight * (a / b)\n",
    "\n",
    "        styles = styles / styles.norm(p = float('inf'), dim = [1], keep_dim = True) # max of inC\n",
    "    \n",
    "    w = None\n",
    "    dcoef = None\n",
    "    if demodulate or fused_mod_cov:\n",
    "        w = weight.unsqueeze(0)                                    # w:      [1, outC, inC, kh, kw]\n",
    "        w = w * styles.reshape(batch_size, 1, -1, 1, 1)            # styles: [B,  1,   inC, 1,  1]\n",
    "                                                                   # w:      [B, outC, inC, kh, kw]\n",
    "    if demodulate:\n",
    "        dcoef = (w.square().sum(dim=[2,3,4]) + 1e-8).rsqrt()       # dcoef:  [B, outC]\n",
    "    \n",
    "    if demodulate and fused_mod_cov:\n",
    "        w = w * dcoef.reshape(batch_size, -1, 1, 1, 1)             # w:      [B, outC, inC, kh, kw]\n",
    "    \n",
    "    if not fused_mod_cov:\n",
    "        x = x * styles.reshape(batch_size, -1, 1, 1)                 # style: [B, inC x kh x kw, C, 1, 1]\n",
    "        x = conv2d_resample.conv2d_resample(x=x, w=weight.to(x.dtype), f=resample_filter, up=up, down=down, padding=padding, flip_weight=flip_weight)\n",
    "        x = x.reshape(batch_size, -1, *x.shape[2:])\n",
    "        if noise is not None:\n",
    "            x = x.add_(noise)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77d73919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6, 26, 26])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modulated_conv2d(\n",
    "    x = torch.rand(5, 3, 10, 10),\n",
    "    weight = torch.rand(6, 3, 5, 5),\n",
    "    styles =  torch.rand(5, 3),\n",
    "    up = 3,\n",
    "    fused_mod_cov = False\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67cf3953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GroupNorm_float32(nn.GroupNorm):\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return super().forward(x.float()).type(x.dtype) # Converts x to float32 -> applies Group norm -> converts back to original type\n",
    "\n",
    "x = torch.randn(8, 32, 64, 64).half()  # float16 tensor\n",
    "\n",
    "gn = GroupNorm_float32(num_groups=8, num_channels=32)\n",
    "y = gn(x)\n",
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8efff91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleSplit(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fcl = FullyConnectedLayers(in_features=in_channels, out_features = 3*out_channels, **kwargs)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.fcl(x)\n",
    "        m1, m2, m3 = x.chunk(chunks=3, dim=1)\n",
    "        return m1 * m2 + m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47173438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = StyleSplit(in_channels=2, out_channels=5)\n",
    "\n",
    "x = torch.rand([10, 2])\n",
    "ss(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c01b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthesisInput(nn.Module):\n",
    "    \"\"\"\n",
    "    Latent w → SynthesisInput → Feature map [B, 64, 64, 64]\n",
    "\n",
    "    sin(2pi (f . x + phi))\n",
    "    \n",
    "    Where:\n",
    "\t•\tf = 2D frequency vector (learned)\n",
    "\t•\tx = pixel location\n",
    "\t•\tphi = phase offset (learned)\n",
    "\t•\tAll of this is modulated by latent vector w through an affine transformation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, w_dim: int, channels: int, size: int, sampling_rate: int, bandwidth: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.w_dim = w_dim\n",
    "        self.channels = channels\n",
    "        self.size = np.broadcast_to(size, [2])\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.bandwidth = bandwidth\n",
    "\n",
    "        # Draw random frequencies from uniform 2D disc.\n",
    "        freqs = torch.rand([3, 2])                                  # Gausian Cloud in 2D space\n",
    "        radii = freqs.square().sum(dim = 1, keepdim=True).sqrt()    #  $r = \\sqrt{x^2 + y^2}$\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b0aa5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0120, 0.0989, 0.9029])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ee079c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4917, 0.4293],\n",
       "        [0.2333, 0.6255],\n",
       "        [0.3529, 0.9713]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = torch.rand([3, 2]) # Gausian Cloud in 2D space\n",
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0cf94bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6527],\n",
       "        [0.6676],\n",
       "        [1.0335]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radii = freqs.square().sum(dim = 1, keepdim=True).sqrt()\n",
    "radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd9e8525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1124],\n",
       "        [1.1179],\n",
       "        [1.3061]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radii.square().exp().pow(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b393b662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
