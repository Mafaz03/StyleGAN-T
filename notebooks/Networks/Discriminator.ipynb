{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6fe5a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "from torch.nn.utils.spectral_norm import SpectralNorm\n",
    "\n",
    "from helper import assert_shape\n",
    "from shared import FullyConnectedLayers, ResidualBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e48be1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 100])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SpectralConv1d(nn.Conv1d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        SpectralNorm.apply(self, name = \"weight\", n_power_iterations=1, dim = 0, eps = 1e-12)\n",
    "\n",
    "# Dummy input: [batch, channels, length]\n",
    "x = torch.randn(5, 64, 100)\n",
    "\n",
    "conv1d_modified = SpectralConv1d(in_channels=64, out_channels=64, kernel_size=7, stride=1, padding = 3)\n",
    "modified_out = conv1d_modified(x)\n",
    "modified_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2314cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 64, 100])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LocalBatchNorm(nn.Module):\n",
    "    # When using large batch sizes, the variance across the batch can be very high, especially in early training.\n",
    "    # It may cause the normalization to overreact, resulting in instability in the discriminatorâ€™s learning.\n",
    "    # So we use virtual_bs for smaller batch size to normalize it through.\n",
    "    def __init__(self, num_features: int, affine: bool = True, virtual_bs: int = 8, eps: float = 1e-8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_features = num_features\n",
    "        self.affine = affine             # learn weight and biases?\n",
    "        self.virtual_bs = virtual_bs\n",
    "        self.eps = eps\n",
    "\n",
    "        if self.affine:\n",
    "            self.weights = nn.Parameter(torch.ones(num_features))\n",
    "            self.bias    = nn.Parameter(torch.zeros(num_features))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        shape = x.shape\n",
    "\n",
    "        G = np.ceil(x.shape[0] / self.virtual_bs).astype(int) # G = B / 8 \n",
    "        x = x.view(G, -1, x.shape[1], x.shape[2])             # x: [G, -1, N, C]\n",
    "        # Normalizing per group, per channel\n",
    "        mean = x.mean([1, 3], keepdim=True)                   # mean: [G, 1, N, 1] \n",
    "        var = x.var([1, 3], keepdim=True)                     # var : [G, 1, N, 1] \n",
    "\n",
    "        x = (x - mean) / (torch.sqrt(var) + self.eps)            # x: [G, -1, N, C]\n",
    "\n",
    "        if self.affine:\n",
    "            x = x * self.weights[None, :, None]               # weight: [1, N, 1]\n",
    "                                                              # x     : [G, -1, N, C]\n",
    "\n",
    "            x = x + self.bias[None, :, None]                  # bias  : [1, N, 1]\n",
    "                                                              # x     : [G, -1, N, C]\n",
    "        return x.view(shape)\n",
    "\n",
    "x = torch.randn(18, 64, 100)\n",
    "\n",
    "lbn = LocalBatchNorm(num_features = 64, affine=True)\n",
    "out = lbn(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cab6bc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 64, 100])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(18, 64, 100)\n",
    "\n",
    "shape = x.shape\n",
    "\n",
    "num_features=64\n",
    "virtual_bs=8\n",
    "eps = 1e-8\n",
    "affine = True\n",
    "\n",
    "weight = nn.Parameter(torch.ones(num_features))\n",
    "bias   = nn.Parameter(torch.zeros(num_features))\n",
    "\n",
    "G = np.ceil(x.shape[0] / virtual_bs).astype(int) # G = 20 / 8 = 3\n",
    "\n",
    "x = x.view(G, -1, x.shape[1], x.shape[2])  # x: [G, -1, N, C]\n",
    "\n",
    "# Normalizing per group, per channel\n",
    "mean = x.mean([1, 3], keepdim=True)        # mean: [G, 1, N, 1] \n",
    "var = x.var([1, 3], keepdim=True)          # var : [G, 1, N, 1] \n",
    "\n",
    "x = (x - mean) / (torch.sqrt(var) + eps)      # x: [G, -1, N, C]\n",
    "if affine: \n",
    "    x = x * weight[None, :, None]          # weight: [1, N, 1]\n",
    "                                           # x     : [G, -1, N, C]\n",
    "\n",
    "    x = x + bias[None, :, None]            # bias  : [1, N, 1]\n",
    "                                           # x     : [G, -1, N, C]\n",
    "x = x.view(shape)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4d10fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 64, 100])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_block(channels: int, kernel_size: int):\n",
    "    return nn.Sequential(\n",
    "        SpectralConv1d(in_channels  = channels, \n",
    "                       out_channels = channels, \n",
    "                       kernel_size  = kernel_size, \n",
    "                       padding      = kernel_size//2, \n",
    "                       padding_mode = \"circular\"),\n",
    "        \n",
    "        LocalBatchNorm(num_features = channels),\n",
    "        nn.LeakyReLU(0.2, True)\n",
    "    )\n",
    "x = torch.rand(5, 64, 100)\n",
    "block = make_block(64, 7)\n",
    "out = block(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdbfc88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(4, 3)\n",
    "f = FullyConnectedLayers(3, 10)\n",
    "f(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f6d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 64])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels = 384 # DINO ViT-S output\n",
    "c_dim    = 512 # Text embedding from CLIP\n",
    "cmap_dim = 64  # Projection space for conditional score\n",
    "\n",
    "x = torch.rand(5, channels, 64)\n",
    "c = torch.rand(5, c_dim)\n",
    "\n",
    "main = nn.Sequential(\n",
    "    make_block(channels = channels, kernel_size = 1),\n",
    "    ResidualBlock(make_block(channels = channels, kernel_size = 9))\n",
    ")   # x shape will remain same as long as kernel is odd\n",
    "\n",
    "cmapper = FullyConnectedLayers(in_features = c_dim, out_features = cmap_dim)\n",
    "cls = SpectralConv1d(in_channels = channels, out_channels = cmap_dim, kernel_size = 1, padding = 0)\n",
    "\n",
    "h = main(x)                         # h: [B, channels, dim]\n",
    "out = cls(h)                        # h: [B, cmap_dim, dim]\n",
    "\n",
    "cmap = cmapper(c)                   # cmap: [B, cmap_dim]\n",
    "cmap = cmap.unsqueeze(-1)           # cmap: [B, cmap_dim, 1]\n",
    "\n",
    "out = out * cmap                    # out:  [B, cmap_dim, cmap_dim]\n",
    "out = out.sum(1, keepdim=True)      # out:  [B, 1,        cmap_dim]\n",
    "out = out * np.sqrt(1 / cmap_dim)   # out:  [B, 1,        cmap_dim]\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2daa5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 64])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DiscHead(nn.Module):\n",
    "    def __init__(self, channels: int, c_dim: int, cmap_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.channels = channels # DINO ViT-S output\n",
    "        self.c_dim = c_dim       # Text embedding from CLIP\n",
    "        self.cmap_dim = cmap_dim # Projection space for conditional score\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            make_block(channels = channels, kernel_size = 1),\n",
    "            ResidualBlock(make_block(channels = channels, kernel_size = 9))\n",
    "        )   # x shape will remain same as long as kernel is odd\n",
    "\n",
    "        if self.c_dim > 0:\n",
    "            self.cmapper = FullyConnectedLayers(in_features = c_dim, out_features = cmap_dim)\n",
    "            self.cls = SpectralConv1d(in_channels = channels, out_channels = cmap_dim, kernel_size = 1, padding = 0)\n",
    "        else:\n",
    "            self.cls = SpectralConv1d(in_channels = channels, out_channels = 1, kernel_size=1, padding=0)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, c: torch.Tensor) -> torch.Tensor:\n",
    "        # x: [B, channels, dim]\n",
    "        # c: [B, c_dim]\n",
    "\n",
    "        h = main(x)                         # h  : [B, channels, dim]\n",
    "        out = cls(h)                        # out: [B, cmap_dim, dim]\n",
    "                                            #         or\n",
    "                                            # out: [B, 1,        dim]\n",
    "        \n",
    "        if self.c_dim > 0:\n",
    "            cmap = cmapper(c)                   # cmap: [B, cmap_dim]\n",
    "            cmap = cmap.unsqueeze(-1)           # cmap: [B, cmap_dim, 1]\n",
    "            out = out * cmap                    # out:  [B, cmap_dim, cmap_dim]\n",
    "            out = out.sum(1, keepdim=True)      # out:  [B, 1,        cmap_dim]\n",
    "            out = out * np.sqrt(1 / cmap_dim)   # out:  [B, 1,        cmap_dim]\n",
    "        \n",
    "        return out\n",
    "\n",
    "channels = 384 # DINO ViT-S output\n",
    "c_dim    = 512 # Text embedding from CLIP\n",
    "cmap_dim = 64  # Projection space for conditional score\n",
    "\n",
    "x = torch.rand(5, channels, 64)\n",
    "c = torch.rand(5, c_dim)\n",
    "\n",
    "dh = DiscHead(channels = 384, c_dim = 512, cmap_dim = 64)\n",
    "out = dh(x, c)\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "834ee81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-8.5590e-01, -6.2695e-01,  1.0369e+00,  ..., -4.0690e-01,\n",
       "            3.0418e-01, -1.6663e-01],\n",
       "          [ 9.2569e-02, -7.4587e-01, -6.3662e-02,  ..., -5.4423e-02,\n",
       "           -9.3662e-01,  1.0096e-02],\n",
       "          [ 1.8786e+00,  1.7799e+00, -1.2064e+00,  ...,  1.3048e-01,\n",
       "           -9.1324e-01,  3.9856e-01],\n",
       "          ...,\n",
       "          [-1.5674e+00, -1.0890e+00, -1.6710e-01,  ...,  1.2371e+00,\n",
       "           -9.5624e-01,  1.1564e+00],\n",
       "          [ 2.1311e+00,  3.4452e+00, -4.3856e-01,  ...,  2.9406e-01,\n",
       "            8.5865e-01,  1.0221e+00],\n",
       "          [-4.0233e-01,  8.6183e-01, -2.7662e-01,  ..., -4.7669e-01,\n",
       "            8.2314e-01,  1.4380e+00]],\n",
       "\n",
       "         [[ 3.4225e-01,  1.4623e+00,  7.6887e-02,  ..., -2.4011e+00,\n",
       "            9.1836e-02,  8.9345e-01],\n",
       "          [-1.0438e+00,  9.6982e-01,  1.6536e+00,  ...,  5.3397e-01,\n",
       "           -5.5397e-01, -3.9121e-01],\n",
       "          [ 4.5912e-01, -4.9155e-01,  2.2737e-01,  ..., -1.3542e+00,\n",
       "           -1.0033e+00, -1.3426e+00],\n",
       "          ...,\n",
       "          [-7.3053e-01,  2.4624e-01,  2.1386e-01,  ..., -1.6922e+00,\n",
       "           -1.1394e+00, -4.2404e-01],\n",
       "          [ 2.1939e+00,  1.7744e+00,  5.1493e-01,  ...,  1.4484e+00,\n",
       "           -5.1666e-01, -6.9608e-01],\n",
       "          [-2.2359e+00,  7.6282e-01,  3.9558e-01,  ...,  5.2930e-01,\n",
       "            9.0683e-01,  2.1132e+00]],\n",
       "\n",
       "         [[-1.1561e-01,  2.5206e-02, -1.2819e+00,  ...,  8.6360e-01,\n",
       "           -2.1096e-01,  2.5315e-01],\n",
       "          [ 1.0002e-01, -7.1935e-01, -1.9046e+00,  ...,  1.3691e+00,\n",
       "            4.5309e-01,  1.5513e+00],\n",
       "          [-5.4202e-01,  2.1216e-01,  1.5792e+00,  ..., -7.7791e-01,\n",
       "           -1.3376e-01,  4.7069e-01],\n",
       "          ...,\n",
       "          [ 1.4464e-01, -6.7442e-01, -3.1714e-01,  ...,  4.0944e-01,\n",
       "            6.8869e-01,  3.8238e-01],\n",
       "          [ 1.7171e+00,  7.3149e-01, -9.1781e-01,  ...,  3.1980e-01,\n",
       "           -2.7312e-02,  2.0358e-02],\n",
       "          [-1.4436e+00, -1.3374e+00,  3.2243e-01,  ..., -1.9140e+00,\n",
       "            9.2939e-01,  7.6163e-01]],\n",
       "\n",
       "         [[ 1.1283e+00, -6.5177e-01,  8.4080e-01,  ...,  4.1565e-01,\n",
       "            3.0709e-01, -7.3446e-01],\n",
       "          [ 9.8796e-01,  1.1685e+00,  1.7813e+00,  ...,  1.3489e+00,\n",
       "           -1.4049e+00,  1.6343e+00],\n",
       "          [ 7.1930e-01,  1.3153e+00, -4.5979e-01,  ...,  3.8812e-01,\n",
       "            1.6943e-01, -3.9715e-01],\n",
       "          ...,\n",
       "          [-4.1691e-01,  3.0966e+00, -2.5651e-01,  ..., -1.2786e-01,\n",
       "            1.2661e+00, -6.8921e-01],\n",
       "          [ 1.6237e+00, -1.2584e+00,  6.7475e-01,  ...,  1.6494e+00,\n",
       "           -9.5263e-01, -5.3077e-01],\n",
       "          [ 3.6163e-01, -1.9058e+00,  7.5889e-01,  ..., -4.0608e-01,\n",
       "            5.9006e-01, -1.5031e+00]],\n",
       "\n",
       "         [[ 3.7459e-01,  2.2287e-01,  1.8668e+00,  ..., -1.8722e-01,\n",
       "           -1.1770e+00,  1.0525e+00],\n",
       "          [-1.0506e+00,  3.7004e-01, -6.7396e-01,  ..., -1.1404e-02,\n",
       "           -8.4277e-01,  1.4186e+00],\n",
       "          [ 1.0855e+00, -6.8767e-01,  7.5243e-01,  ...,  3.6940e-01,\n",
       "           -1.5104e+00,  5.8691e-02],\n",
       "          ...,\n",
       "          [-4.1053e-01, -2.0039e+00, -1.7691e+00,  ..., -5.3669e-01,\n",
       "            4.2154e-01,  2.0382e+00],\n",
       "          [ 3.2841e-01, -3.1201e-01,  1.7792e-01,  ..., -9.1930e-01,\n",
       "            2.6045e+00,  4.7358e-01],\n",
       "          [-7.2185e-01, -1.6340e+00, -3.6292e-01,  ..., -4.5477e-01,\n",
       "           -1.8601e+00,  1.3718e+00]],\n",
       "\n",
       "         [[-5.4953e-01, -1.4905e+00, -1.3666e+00,  ...,  1.8580e+00,\n",
       "           -3.4243e-01,  2.2437e-01],\n",
       "          [ 1.2213e+00, -1.2200e+00,  2.4192e-01,  ..., -7.3757e-01,\n",
       "            1.3395e+00, -5.1266e-01],\n",
       "          [ 1.1035e+00, -2.0287e-01,  1.2139e+00,  ..., -1.1046e+00,\n",
       "           -8.0054e-01,  7.0133e-01],\n",
       "          ...,\n",
       "          [ 1.7175e+00, -4.8210e-02,  5.5053e-02,  ...,  4.9552e-01,\n",
       "            3.7849e-01,  1.8387e-01],\n",
       "          [-4.8844e-01, -1.8350e+00, -8.3243e-01,  ..., -8.3237e-01,\n",
       "           -7.0018e-01,  1.0035e+00],\n",
       "          [-5.7288e-01,  3.5785e-02,  2.3557e-01,  ...,  8.0212e-01,\n",
       "           -6.4668e-02,  1.1886e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1260e+00,  1.7483e+00, -1.2791e+00,  ...,  1.4556e+00,\n",
       "            7.9458e-01, -8.7884e-02],\n",
       "          [-6.3103e-01,  7.4016e-01, -2.5791e-01,  ...,  6.1976e-01,\n",
       "           -2.0091e-01, -5.0103e-01],\n",
       "          [-4.0331e-01, -7.6875e-01, -8.7799e-01,  ..., -2.4046e-01,\n",
       "           -9.9631e-01, -5.2998e-01],\n",
       "          ...,\n",
       "          [-2.8114e-01, -1.4193e-01, -4.8583e-01,  ...,  3.8324e-01,\n",
       "            9.2664e-01, -3.8275e-01],\n",
       "          [ 7.4719e-01,  6.9139e-01,  8.0279e-01,  ...,  5.5540e-01,\n",
       "            1.5098e+00, -1.5568e+00],\n",
       "          [ 1.7075e+00,  2.8356e-01,  3.7886e-01,  ..., -3.9852e-01,\n",
       "           -1.6283e+00, -1.7420e+00]],\n",
       "\n",
       "         [[-5.0481e-02, -4.0417e-01, -4.3054e-01,  ...,  1.1720e+00,\n",
       "            1.2587e+00,  6.3950e-03],\n",
       "          [ 1.0095e+00, -3.1906e-01,  1.4895e+00,  ..., -1.2049e+00,\n",
       "           -8.0594e-01, -4.1079e-01],\n",
       "          [-1.5469e+00,  2.7527e+00,  5.1575e-01,  ..., -7.0015e-01,\n",
       "           -7.4903e-01, -1.1947e+00],\n",
       "          ...,\n",
       "          [-1.0632e+00, -1.5941e+00,  4.0177e-01,  ...,  6.7401e-01,\n",
       "            5.0982e-01, -7.6764e-01],\n",
       "          [-7.0261e-01,  9.6794e-01,  7.5769e-01,  ...,  1.5123e+00,\n",
       "            1.5284e-01, -1.0515e+00],\n",
       "          [-2.7751e-01,  7.7941e-01, -1.0083e+00,  ..., -3.4799e-01,\n",
       "            5.9236e-01, -2.0931e+00]],\n",
       "\n",
       "         [[-6.5518e-02, -7.9842e-01,  2.7788e-01,  ..., -5.1647e-02,\n",
       "            3.9682e-01,  4.2561e-01],\n",
       "          [-5.5999e-02, -4.5067e-01,  1.0838e+00,  ..., -1.1726e+00,\n",
       "           -1.6860e+00,  7.1484e-01],\n",
       "          [-1.8872e-01, -1.0718e+00, -1.0308e+00,  ...,  9.0532e-01,\n",
       "           -9.6986e-01, -1.1057e+00],\n",
       "          ...,\n",
       "          [-2.7377e-01, -1.8466e+00, -3.1148e+00,  ..., -1.3963e+00,\n",
       "           -6.2182e-01, -1.0552e+00],\n",
       "          [ 6.8083e-01, -1.9951e+00,  1.2937e+00,  ...,  1.6679e-01,\n",
       "            1.4252e+00,  9.9299e-01],\n",
       "          [ 1.1651e+00, -6.1701e-01, -1.9309e+00,  ...,  4.7638e-01,\n",
       "           -5.2231e-01,  1.6696e+00]],\n",
       "\n",
       "         [[-6.9014e-01, -4.7826e-01,  7.4675e-01,  ...,  2.9828e-01,\n",
       "            5.3061e-01, -2.1577e-01],\n",
       "          [-7.4404e-02,  1.3345e+00, -1.8849e+00,  ...,  2.3417e-01,\n",
       "            4.2350e-01,  1.4821e+00],\n",
       "          [ 1.2029e+00, -7.4441e-01,  7.1426e-01,  ...,  1.4050e+00,\n",
       "           -2.1535e-01,  1.1249e+00],\n",
       "          ...,\n",
       "          [-9.9294e-01, -4.5246e-01, -1.0872e+00,  ...,  1.3851e+00,\n",
       "           -8.2663e-02,  1.6867e+00],\n",
       "          [-9.0936e-01,  1.2695e+00, -5.0778e-01,  ...,  4.1975e-01,\n",
       "           -5.6253e-01,  4.8199e-01],\n",
       "          [ 3.6205e-01, -2.4640e-01, -9.1588e-01,  ...,  3.0052e-01,\n",
       "            1.5709e+00,  5.1241e-01]],\n",
       "\n",
       "         [[ 1.0921e-01,  1.3708e+00,  1.3542e-01,  ...,  5.7394e-01,\n",
       "            7.9090e-01,  1.0640e+00],\n",
       "          [-9.6837e-01, -5.1585e-01,  3.8818e-01,  ..., -2.7580e-01,\n",
       "           -6.2818e-02,  1.1178e+00],\n",
       "          [ 2.3189e-02,  2.2095e-01,  6.4714e-01,  ..., -1.4605e+00,\n",
       "            1.6395e-01,  1.3916e+00],\n",
       "          ...,\n",
       "          [ 2.0538e+00,  2.6000e-01, -2.1974e+00,  ...,  5.6674e-01,\n",
       "           -8.3931e-01, -1.2418e+00],\n",
       "          [-1.7749e+00,  7.3294e-01, -9.5892e-01,  ..., -3.1421e-01,\n",
       "            1.2687e+00,  6.3560e-01],\n",
       "          [ 5.0969e-01, -1.3008e+00,  1.7027e+00,  ..., -1.8114e-01,\n",
       "           -1.2377e+00,  1.5917e+00]],\n",
       "\n",
       "         [[-6.7752e-02,  1.6767e+00,  3.7022e-01,  ...,  5.4965e-01,\n",
       "           -1.3381e+00, -1.1659e+00],\n",
       "          [-1.1476e+00, -4.3361e-01,  4.8691e-01,  ..., -1.5705e+00,\n",
       "            1.0662e+00,  3.7617e-01],\n",
       "          [-3.3422e-01, -4.4743e-02,  1.0174e+00,  ..., -1.1239e+00,\n",
       "            3.9161e-01, -1.3900e+00],\n",
       "          ...,\n",
       "          [-1.5461e+00,  7.6569e-01, -3.6561e-01,  ..., -3.0403e-03,\n",
       "            1.1322e+00, -7.8780e-02],\n",
       "          [-8.1381e-01,  2.4456e+00, -3.6460e-01,  ..., -1.7915e+00,\n",
       "           -1.1382e+00, -1.4066e+00],\n",
       "          [-4.2121e-01,  2.6694e-01,  9.0260e-02,  ...,  2.4310e+00,\n",
       "           -1.4870e+00,  1.7213e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7245e+00, -1.5232e-01, -1.6496e+00,  ..., -1.0890e+00,\n",
       "            1.9062e+00, -4.3317e-01],\n",
       "          [ 1.5223e+00, -1.1665e+00, -1.1291e+00,  ..., -2.2049e+00,\n",
       "           -1.3759e+00, -1.2724e-02],\n",
       "          [-6.1214e-02, -1.5902e+00, -1.3690e+00,  ...,  1.9849e+00,\n",
       "           -1.5730e-01, -1.3665e+00],\n",
       "          ...,\n",
       "          [-3.5255e-01,  4.9366e-01, -1.7956e-01,  ..., -2.4768e-01,\n",
       "            9.3476e-01, -1.8535e-01],\n",
       "          [ 2.6833e-01, -3.8458e+00,  2.5135e-01,  ..., -6.5774e-01,\n",
       "           -3.3667e-01,  4.3359e-01],\n",
       "          [ 5.9704e-01,  1.9210e+00, -5.6690e-01,  ..., -1.2415e+00,\n",
       "           -7.4157e-01, -1.9186e+00]],\n",
       "\n",
       "         [[ 5.1729e-01, -1.2313e+00,  4.4800e-01,  ..., -1.4066e+00,\n",
       "           -1.2277e+00,  7.5029e-01],\n",
       "          [-1.0128e+00,  1.5785e-01,  4.5605e-02,  ...,  1.4082e+00,\n",
       "            2.5825e-01, -6.1217e-01],\n",
       "          [-7.7672e-01, -7.3663e-01,  1.0013e-01,  ..., -2.4301e-01,\n",
       "            8.9978e-01,  2.0357e-01],\n",
       "          ...,\n",
       "          [-4.0609e-01,  1.1239e+00, -4.0100e-01,  ...,  9.0386e-02,\n",
       "            6.7276e-02,  8.0207e-02],\n",
       "          [-1.1246e+00, -1.3051e+00,  1.3773e+00,  ..., -1.4450e+00,\n",
       "            1.3538e+00, -5.8446e-01],\n",
       "          [ 4.1525e-01,  1.1505e+00, -2.5670e-02,  ..., -6.9208e-01,\n",
       "            3.9950e-01, -1.2148e+00]],\n",
       "\n",
       "         [[ 5.5466e-01,  5.7926e-01,  9.3111e-01,  ...,  7.5072e-01,\n",
       "           -2.1577e-01, -1.1469e+00],\n",
       "          [ 1.2638e+00, -5.6406e-01, -2.0481e+00,  ..., -2.7920e+00,\n",
       "            8.9074e-01, -1.8107e+00],\n",
       "          [-1.4568e+00,  6.0419e-01, -1.7653e+00,  ..., -5.0373e-01,\n",
       "            1.1267e+00,  1.2044e+00],\n",
       "          ...,\n",
       "          [-6.4887e-01, -1.2460e-01,  6.7842e-01,  ...,  1.4011e+00,\n",
       "            1.7850e+00, -7.9582e-01],\n",
       "          [-8.4168e-01, -8.4961e-01,  1.4367e-01,  ...,  1.8921e-01,\n",
       "            2.0925e-01,  7.6147e-01],\n",
       "          [ 4.1794e-01,  1.4954e+00,  6.7025e-01,  ...,  1.0179e+00,\n",
       "            1.4716e+00, -5.5594e-02]],\n",
       "\n",
       "         [[-6.6269e-01,  4.7531e-01, -1.1762e+00,  ..., -3.1233e-01,\n",
       "           -5.9915e-01, -1.0295e+00],\n",
       "          [-1.4437e+00,  9.3744e-01,  6.6261e-01,  ...,  3.2101e-01,\n",
       "           -2.6496e+00, -9.5965e-01],\n",
       "          [-4.0886e-01, -1.0722e+00,  2.1678e-01,  ...,  5.8597e-02,\n",
       "           -8.2986e-01,  3.0644e+00],\n",
       "          ...,\n",
       "          [ 7.4977e-01, -5.7844e-01,  5.7194e-01,  ...,  7.9968e-01,\n",
       "           -1.5619e+00,  1.2304e+00],\n",
       "          [ 5.5872e-01, -9.2663e-01, -1.0307e+00,  ...,  1.0031e+00,\n",
       "            8.8435e-01,  2.9755e-01],\n",
       "          [ 7.8585e-01,  3.0892e-01, -1.4100e+00,  ..., -5.7800e-01,\n",
       "            1.5596e+00, -3.0901e-01]],\n",
       "\n",
       "         [[ 2.8690e-01,  2.6925e-01, -1.0423e+00,  ...,  1.1128e+00,\n",
       "           -7.5456e-01,  1.2926e+00],\n",
       "          [ 7.0279e-01, -5.1869e-01,  7.4244e-01,  ...,  2.0786e+00,\n",
       "           -4.4541e-01, -1.0275e-01],\n",
       "          [-1.1077e+00,  1.7031e+00, -3.1295e-01,  ..., -2.5803e+00,\n",
       "           -1.4653e+00,  1.1734e+00],\n",
       "          ...,\n",
       "          [ 3.3437e+00, -7.1115e-01,  1.3109e+00,  ..., -9.4630e-01,\n",
       "           -4.7228e-01, -6.0590e-01],\n",
       "          [-5.1757e-01, -9.4240e-01,  1.0754e+00,  ..., -1.7710e-01,\n",
       "           -1.9169e+00, -3.2486e-01],\n",
       "          [-5.7275e-01, -2.1787e-01,  1.5156e+00,  ..., -8.6073e-01,\n",
       "            6.1310e-01,  1.5387e+00]],\n",
       "\n",
       "         [[ 1.4036e+00, -2.4489e-01, -2.0291e-01,  ...,  7.7568e-01,\n",
       "            3.3817e-01,  3.8549e-01],\n",
       "          [ 6.7907e-01, -7.1776e-01,  5.3596e-01,  ..., -1.2007e+00,\n",
       "            9.9336e-02,  3.1538e-01],\n",
       "          [-1.4912e+00,  6.6556e-01,  4.0986e-01,  ..., -1.1611e+00,\n",
       "           -5.3391e-02,  4.4089e-01],\n",
       "          ...,\n",
       "          [-9.6565e-01, -1.7130e-01,  3.4537e-01,  ..., -9.1482e-02,\n",
       "           -5.4494e-01,  2.0051e-01],\n",
       "          [ 7.3981e-01, -7.0496e-02,  1.4999e+00,  ..., -5.4522e-02,\n",
       "           -1.7472e-01, -9.9199e-02],\n",
       "          [-9.2014e-01, -1.0138e-01, -6.1341e-02,  ...,  3.7747e-01,\n",
       "           -5.6437e-01,  2.9979e-02]]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(G, -1, x.shape[1], x.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c3ea23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
