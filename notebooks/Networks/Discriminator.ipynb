{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f6fe5a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "from torch.nn.utils.spectral_norm import SpectralNorm\n",
    "\n",
    "from helper import assert_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e48be1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 128, 96])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SpectralConv1d(nn.Conv1d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        SpectralNorm.apply(self, name = \"weight\", n_power_iterations=1, dim = 0, eps = 1e-12)\n",
    "\n",
    "# Dummy input: [batch, channels, length]\n",
    "x = torch.randn(5, 64, 100)\n",
    "\n",
    "conv1d_modified = SpectralConv1d(in_channels=64, out_channels=128, kernel_size=5, stride=1)\n",
    "modified_out = conv1d_modified(x)\n",
    "modified_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c2314cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 64, 100])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LocalBatchNorm(nn.Module):\n",
    "    # When using large batch sizes, the variance across the batch can be very high, especially in early training.\n",
    "    # It may cause the normalization to overreact, resulting in instability in the discriminatorâ€™s learning.\n",
    "    # So we use virtual_bs for smaller batch size to normalize it through.\n",
    "    def __init__(self, num_features: int, affine: bool, virtual_bs: int = 8, eps: float = 1e-8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_features = num_features\n",
    "        self.affine = affine             # learn weight and biases?\n",
    "        self.virtual_bs = virtual_bs\n",
    "        self.eps = eps\n",
    "\n",
    "        if self.affine:\n",
    "            self.weights = nn.Parameter(torch.ones(num_features))\n",
    "            self.bias    = nn.Parameter(torch.zeros(num_features))\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        shape = x.shape\n",
    "\n",
    "        G = np.ceil(x.shape[0] / self.virtual_bs).astype(int) # G = B / 8 \n",
    "        x = x.view(G, -1, x.shape[1], x.shape[2])             # x: [G, -1, N, C]\n",
    "        # Normalizing per group, per channel\n",
    "        mean = x.mean([1, 3], keepdim=True)        # mean: [G, 1, N, 1] \n",
    "        var = x.var([1, 3], keepdim=True)          # var : [G, 1, N, 1] \n",
    "\n",
    "        x = (x - mean) / (np.sqrt(var) + self.eps)      # x: [G, -1, N, C]\n",
    "\n",
    "        if self.affine:\n",
    "            x = x * self.weights[None, :, None]      # weight: [1, N, 1]\n",
    "                                                    # x     : [G, -1, N, C]\n",
    "\n",
    "            x = x + self.bias[None, :, None]        # bias  : [1, N, 1]\n",
    "                                                    # x     : [G, -1, N, C]\n",
    "        return x.view(shape)\n",
    "\n",
    "x = torch.randn(18, 64, 100)\n",
    "\n",
    "lbn = LocalBatchNorm(num_features = 64, affine=True)\n",
    "out = lbn(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cab6bc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 64, 100])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(18, 64, 100)\n",
    "\n",
    "shape = x.shape\n",
    "\n",
    "num_features=64\n",
    "virtual_bs=8\n",
    "eps = 1e-8\n",
    "affine = True\n",
    "\n",
    "weight = nn.Parameter(torch.ones(num_features))\n",
    "bias   = nn.Parameter(torch.zeros(num_features))\n",
    "\n",
    "G = np.ceil(x.shape[0] / virtual_bs).astype(int) # G = 20 / 8 = 3\n",
    "\n",
    "x = x.view(G, -1, x.shape[1], x.shape[2])  # x: [G, -1, N, C]\n",
    "\n",
    "# Normalizing per group, per channel\n",
    "mean = x.mean([1, 3], keepdim=True)        # mean: [G, 1, N, 1] \n",
    "var = x.var([1, 3], keepdim=True)          # var : [G, 1, N, 1] \n",
    "\n",
    "x = (x - mean) / (np.sqrt(var) + eps)      # x: [G, -1, N, C]\n",
    "if affine: \n",
    "    x = x * weight[None, :, None]          # weight: [1, N, 1]\n",
    "                                           # x     : [G, -1, N, C]\n",
    "\n",
    "    x = x + bias[None, :, None]            # bias  : [1, N, 1]\n",
    "                                           # x     : [G, -1, N, C]\n",
    "x = x.view(shape)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c4d10fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias[None, : None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d33f6d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape[0] / 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "834ee81a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[3, -1, 64, 100]' is invalid for input of size 128000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[3, -1, 64, 100]' is invalid for input of size 128000"
     ]
    }
   ],
   "source": [
    "x.view(G, -1, x.shape[1], x.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c3ea23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
