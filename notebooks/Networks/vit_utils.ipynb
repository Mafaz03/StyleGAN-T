{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d4f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import math\n",
    "from typing import Callable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe46c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name vit_small_patch16_224_dino to current vit_small_patch16_224.dino.\n",
      "  model = create_fn(\n"
     ]
    }
   ],
   "source": [
    "dino = timm.create_model('vit_small_patch16_224_dino', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9e548e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = [16, 16]\n",
    "hooks = [2, 5, 8, 11]\n",
    "hook_patch = True\n",
    "start_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cd67d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = nn.Module()\n",
    "pretrained.model = dino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "11f78a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "def get_activation(name: str) -> Callable:\n",
    "    def hook(model, inputs, outputs):\n",
    "        activations[name] = outputs\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c71bc808",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(hooks)):\n",
    "    pretrained.model.blocks[hooks[i]].register_forward_hook(get_activation(f'{i}')) # Get shape of 2nd, 5th, 6th... Block of ViT\n",
    "if hook_patch: pretrained.model.pos_drop.register_forward_hook(get_activation('4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b823c4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 384])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dino.eval()\n",
    "output = dino(torch.rand(5, 3, 224, 224))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c375b4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 2 Shape: [5, 197, 384]\n",
      "Block 5 Shape: [5, 197, 384]\n",
      "Block 8 Shape: [5, 197, 384]\n",
      "Block 11 Shape: [5, 197, 384]\n",
      "Dropout Block Shape: [5, 197, 384]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(hooks)):\n",
    "    print(f\"Block {hooks[i]} Shape:\", list(activations[f'{i}'].shape))\n",
    "if hook_patch:\n",
    "    print(f\"Dropout Block Shape:\", list(activations['4'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c663ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 197, 384]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(activations['4'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98bf0851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B = batch size\n",
    "# N = number of tokens\n",
    "# C = embedding dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2822da4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 76, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 5\n",
    "N = 77\n",
    "C = 768\n",
    "start_index = 1\n",
    "\n",
    "x = torch.rand(B, N, C) # [5, 77, 768]\n",
    "\n",
    "# Every local patch token gains global context\n",
    "if start_index == 2:\n",
    "    readout = (x[:, 0] + x[:, 1]) / 2 # (CLS + DIST) / 2\n",
    "else:\n",
    "    readout = x[:, 0]                 # CLS\n",
    "\n",
    "# readout: [B,             C]\n",
    "# x      : [B, N - 2 or 1, C]\n",
    "out = x[: , start_index:] + readout.unsqueeze(1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03444a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 76, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Readout(nn.Module):\n",
    "    \"\"\"\n",
    "    Adds CLS and/or DIST Tokens to the patches\n",
    "    \"\"\"\n",
    "    def __init__(self, start_index = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.start_index = start_index\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # X [B, N, C]\n",
    "        # Every local patch token gains global context\n",
    "        if self.start_index == 2:\n",
    "            readout = (x[:, 0] + x[:, 1]) / 2 # (CLS + DIST) / 2\n",
    "        else:\n",
    "            readout = x[:, 0]                 # CLS\n",
    "        \n",
    "        # readout: [B,             C]\n",
    "        # x      : [B, N - 2 or 1, C]\n",
    "        return x[: , self.start_index: ] + readout.unsqueeze(1)\n",
    "\n",
    "readout = Readout(start_index=1)\n",
    "readout(torch.rand(5, 77, 768)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d896a290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 768, 77])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Transpose(nn.Module):\n",
    "    \"\"\"\n",
    "    from [B, N, C] to [B, C, N]\n",
    "    \"\"\"\n",
    "    def __init__(self, dim1: int, dim2: int):\n",
    "        super().__init__()\n",
    "        self.dim1 = dim1\n",
    "        self.dim2 = dim2\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x.transpose(self.dim1, self.dim2).contiguous()\n",
    "\n",
    "transpose = Transpose(1, 2)\n",
    "transpose(torch.rand(5, 77, 768)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c5b4530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 577, 384])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _resize_pos_embed\n",
    "\n",
    "start_index = 1\n",
    "pos_embed = torch.rand(5, 197, 384)\n",
    "gs_h = gs_w = 24\n",
    "\n",
    "posemb_tok = pos_embed[:, :start_index]                     # posemb_tok:  [B,          1 or 2, C]\n",
    "posemb_grid = pos_embed[0, start_index: ]                   # posemb_grid: [N - 1 or 2, C]\n",
    "\n",
    "gs_old = int(math.sqrt(len(posemb_grid)))                   # gs_old, 14 or 16 .....\n",
    "\n",
    "posemb_grid = posemb_grid.reshape(1, gs_old, gs_old, -1)    # posemb_grid: [1, 14, 14, C]\n",
    "posemb_grid = posemb_grid.permute(0, 3, 1, 2)               # posemb_grid: [1, C, 14, 14]\n",
    "posemb_grid = F.interpolate(posemb_grid, size=(gs_h, gs_w), \n",
    "                            mode=\"bilinear\", \n",
    "                            align_corners=False)            # posemb_grid: [1, C, new_gs_w, new_gs_w]\n",
    "posemb_grid = posemb_grid.permute(0, 2, 3, 1)               # posemb_grid: [1, new_gs_w, new_gs_w, C]\n",
    "posemb_grid = posemb_grid.reshape(1, gs_h * gs_w, -1)       # posemb_grid: [1, new_gs_w x new_gs_w, C]\n",
    "posemb_grid = posemb_grid.expand(pos_embed.shape[0], -1, -1)# posemb_grid: [B, new_gs_w x new_gs_w, C]           added Batch dim back\n",
    "posemb = torch.cat([posemb_tok, posemb_grid], dim = 1)      # posemb_grid: [B, new_gs_w x new_gs_w + 1 or 2, C]  + 1 or 2 CLS token in dim = 1\n",
    "posemb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5738d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 577, 384])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _resize_pos_embed(self, posemb: torch.Tensor, gs_h: int, gs_w: int) -> torch.Tensor:\n",
    "    posemb_tok = pos_embed[:, : self.start_index]                    # posemb_tok:  [B,          1 or 2, C]\n",
    "    posemb_grid = pos_embed[0, self.start_index :]                   # posemb_grid: [N - 1 or 2, C]\n",
    "\n",
    "    gs_old = int(math.sqrt(len(posemb_grid)))                   # gs_old, 14 or 16 .....\n",
    "\n",
    "    posemb_grid = posemb_grid.reshape(1, gs_old, gs_old, -1)    # posemb_grid: [1, 14, 14, C]\n",
    "    posemb_grid = posemb_grid.permute(0, 3, 1, 2)               # posemb_grid: [1, C, 14, 14]\n",
    "    posemb_grid = F.interpolate(posemb_grid, size=(gs_h, gs_w), \n",
    "                                mode=\"bilinear\", \n",
    "                                align_corners=False)            # posemb_grid: [1, C, new_gs_w, new_gs_w]\n",
    "    \n",
    "    posemb_grid = posemb_grid.permute(0, 2, 3, 1)               # posemb_grid: [1, new_gs_w, new_gs_w, C]\n",
    "    posemb_grid = posemb_grid.reshape(1, gs_h * gs_w, -1)       # posemb_grid: [1, new_gs_w x new_gs_w, C]\n",
    "    posemb_grid = posemb_grid.expand(pos_embed.shape[0], -1, -1)# posemb_grid: [B, new_gs_w x new_gs_w, C]    # FIX\n",
    "    posemb = torch.cat([posemb_tok, posemb_grid], dim = 1)      # posemb_grid: [B, new_gs_w x new_gs_w + 1 or 2, C] added Batch dim back + 1 or 2 CLS token\n",
    "    return posemb\n",
    "\n",
    "dino.start_index = 1\n",
    "out = _resize_pos_embed(self = dino, posemb = torch.rand(5, 196, 384), gs_h = 24, gs_w = 24)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b90038d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dino.patch_size = patch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "874811d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 257, 384])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 3, 256, 256)\n",
    "x = pretrained.model.patch_embed.proj(x) # x: [B, embedding dimension, H // 16   W // 16]\n",
    "x = x.flatten(2)                         # x: [B, embedding dimension, H // 16 x W // 16]\n",
    "x = x.transpose(1,2)                     # x: [B, H // 16 x W // 16, embedding dimension]\n",
    "# x: [B, patch_dim, embedding dimension]\n",
    "# x: [B, N,         C]\n",
    "\n",
    "pos_embed = _resize_pos_embed(self = dino, posemb = dino.pos_embed, gs_h = dino.patch_size[0], gs_w = dino.patch_size[1])\n",
    "\n",
    "# # Adding CLS Tokens\n",
    "cls_tokens = pretrained.model.cls_token             # cls_tokens: [1, 1, embedding dimension]\n",
    "cls_tokens = cls_tokens.expand(x.shape[0], -1, -1)  # cls_tokens: [B, 1, embedding dimension]\n",
    "\n",
    "x = torch.cat([cls_tokens, x], dim=1)               # x:   [B, N + 1, C]\n",
    "\n",
    "assert x.shape == pos_embed.shape, f\"x shape: {x.shape}, pos_embed: {pos_embed.shape}\"\n",
    "x = x + pos_embed\n",
    "x = pretrained.model.pos_drop(x)                # x:   [B, N + 1, C]\n",
    "for blk in pretrained.model.blocks:\n",
    "    x = blk(x)                                  # x:   [B, N + 1, C]\n",
    "x = pretrained.model.norm(x)                    # x:   [B, N + 1, C]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9751fee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 257, 384])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward_flex(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = self.patch_embed.proj(x)             # x: [B, embedding dimension, H // 16   W // 16]\n",
    "    x = x.flatten(2)                         # x: [B, embedding dimension, H // 16 x W // 16]\n",
    "    x = x.transpose(1,2)                     # x: [B, H // 16 x W // 16, embedding dimension]\n",
    "    # x: [B, patch_dim, embedding dimension]\n",
    "    # x: [B, N,         C]\n",
    "\n",
    "    pos_embed = _resize_pos_embed(self = self, posemb = self.pos_embed, gs_h = self.patch_size[0], gs_w = self.patch_size[1])\n",
    "\n",
    "    # # Adding CLS Tokens\n",
    "    cls_tokens = self.cls_token             # cls_tokens: [1, 1, embedding dimension]\n",
    "    cls_tokens = cls_tokens.expand(x.shape[0], -1, -1)  # cls_tokens: [B, 1, embedding dimension]\n",
    "\n",
    "    x = torch.cat([cls_tokens, x], dim=1)               # x:   [B, N + 1, C]\n",
    "\n",
    "    assert x.shape == pos_embed.shape, f\"x shape: {x.shape}, pos_embed: {pos_embed.shape}\"\n",
    "    x = x + pos_embed\n",
    "    x = self.pos_drop(x)                # x:   [B, N + 1, C]\n",
    "    for blk in self.blocks:\n",
    "        x = blk(x)                                  # x:   [B, N + 1, C]\n",
    "    x = self.norm(x)                    # x:   [B, N + 1, C]\n",
    "    return x\n",
    "\n",
    "x = torch.rand(5, 3, 256, 256)\n",
    "out = forward_flex(self = pretrained.model, x = x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "618b403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_vit(pretrained: nn.Module, x: torch.Tensor) -> torch.Tensor:\n",
    "    _ = pretrained.model.forward_flex(x) # No need to store output because the dict `activations` gets updated during ReadOut\n",
    "    return {k: pretrained.rearrange(v) for k, v in activations.items()}\n",
    "\n",
    "pretrained.model.forward_flex = types.MethodType(forward_flex, pretrained.model)\n",
    "pretrained.model._resize_pos_embed = types.MethodType(_resize_pos_embed, pretrained.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1399c680",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f706c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_vit_backbone(model: nn.Module, \n",
    "                      patch_size = [16, 16],\n",
    "                      hooks = [2, 5, 8, 11],\n",
    "                      hook_patch = True,\n",
    "                      start_index = 1):\n",
    "    assert len(hooks) == 4\n",
    "    pretained = nn.Module\n",
    "    pretained.model = model\n",
    "\n",
    "    for i in range(len(hooks)):\n",
    "\n",
    "        pretrained.model.blocks[hooks[i]].register_forward_hook(get_activation(f'{i}')) # Get shape of 2nd, 5th, 6th... Block of ViT\n",
    "    if hook_patch: pretrained.model.pos_drop.register_forward_hook(get_activation('4'))\n",
    "\n",
    "    pretrained.rearrange = nn.Sequential(\n",
    "                                        Readout(start_index=start_index), \n",
    "                                        Transpose(1, 2)                  # [B, C, N]\n",
    "                                        )\n",
    "    \n",
    "    pretrained.model.start_index = start_index\n",
    "    pretrained.model.patch_size = patch_size\n",
    "\n",
    "    pretrained.model.forward_flex = types.MethodType(forward_flex, pretrained.model)\n",
    "    pretrained.model._resize_pos_embed = types.MethodType(_resize_pos_embed, pretrained.model)\n",
    "\n",
    "    return pretrained\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "25963b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VisionTransformer'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretained_dino = make_vit_backbone(model = dino)\n",
    "pretained_dino.model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9a0107d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 384])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.rand(5, 3, 224, 224)\n",
    "\n",
    "pretained_dino.model.eval()\n",
    "out1 = pretained_dino.model(img)\n",
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e959d00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 2 Shape: [5, 197, 384]\n",
      "Block 5 Shape: [5, 197, 384]\n",
      "Block 8 Shape: [5, 197, 384]\n",
      "Block 11 Shape: [5, 197, 384]\n",
      "Dropout Block Shape: [5, 197, 384]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(hooks)):\n",
    "    print(f\"Block {hooks[i]} Shape:\", list(activations[f'{i}'].shape))\n",
    "if hook_patch:\n",
    "    print(f\"Dropout Block Shape:\", list(activations['4'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "24d60919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 768, 76])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 77, 768)\n",
    "\n",
    "out2 = pretained_dino.rearrange(x)\n",
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ad176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 257, 384])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 3, 256, 256)\n",
    "\n",
    "out2 = pretained_dino.model.forward_flex(x)\n",
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5f3f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dino.start_index = 1\n",
    "out = _resize_pos_embed(self = dino, posemb = torch.rand(5, 196, 384), gs_h = 24, gs_w = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d00bb0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 577, 384])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 196, 384)\n",
    "\n",
    "out2 = pretained_dino.model._resize_pos_embed(posemb = x, gs_h = 24, gs_w = 24)\n",
    "out2.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
